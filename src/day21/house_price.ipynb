{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb46cbe",
   "metadata": {},
   "source": [
    "# House Price Prediction - ML Workflow\n",
    "\n",
    "This notebook demonstrates a complete machine learning workflow:\n",
    "1. **Data Loading & Exploration** - Understanding the dataset\n",
    "2. **Data Preparation** - Creating features (X) and target (y)\n",
    "3. **Train-Test Split** - Dividing data for training and evaluation\n",
    "4. **Model Training** - Training a regression model\n",
    "5. **Prediction & Evaluation** - Making predictions and assessing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e69b492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DATASET OVERVIEW\n",
      "==================================================\n",
      "Dataset shape: (4600, 18)\n",
      "\n",
      "First few rows:\n",
      "                  date      price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
      "0  2014-05-02 00:00:00   313000.0       3.0       1.50         1340      7912   \n",
      "1  2014-05-02 00:00:00  2384000.0       5.0       2.50         3650      9050   \n",
      "2  2014-05-02 00:00:00   342000.0       3.0       2.00         1930     11947   \n",
      "3  2014-05-02 00:00:00   420000.0       3.0       2.25         2000      8030   \n",
      "4  2014-05-02 00:00:00   550000.0       4.0       2.50         1940     10500   \n",
      "\n",
      "   floors  waterfront  view  condition  sqft_above  sqft_basement  yr_built  \\\n",
      "0     1.5           0     0          3        1340              0      1955   \n",
      "1     2.0           0     4          5        3370            280      1921   \n",
      "2     1.0           0     0          4        1930              0      1966   \n",
      "3     1.0           0     0          4        1000           1000      1963   \n",
      "4     1.0           0     0          4        1140            800      1976   \n",
      "\n",
      "   yr_renovated                    street       city  statezip country  \n",
      "0          2005      18810 Densmore Ave N  Shoreline  WA 98133     USA  \n",
      "1             0           709 W Blaine St    Seattle  WA 98119     USA  \n",
      "2             0  26206-26214 143rd Ave SE       Kent  WA 98042     USA  \n",
      "3             0           857 170th Pl NE   Bellevue  WA 98008     USA  \n",
      "4          1992         9105 170th Ave NE    Redmond  WA 98052     USA  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           4600 non-null   object \n",
      " 1   price          4600 non-null   float64\n",
      " 2   bedrooms       4600 non-null   float64\n",
      " 3   bathrooms      4600 non-null   float64\n",
      " 4   sqft_living    4600 non-null   int64  \n",
      " 5   sqft_lot       4600 non-null   int64  \n",
      " 6   floors         4600 non-null   float64\n",
      " 7   waterfront     4600 non-null   int64  \n",
      " 8   view           4600 non-null   int64  \n",
      " 9   condition      4600 non-null   int64  \n",
      " 10  sqft_above     4600 non-null   int64  \n",
      " 11  sqft_basement  4600 non-null   int64  \n",
      " 12  yr_built       4600 non-null   int64  \n",
      " 13  yr_renovated   4600 non-null   int64  \n",
      " 14  street         4600 non-null   object \n",
      " 15  city           4600 non-null   object \n",
      " 16  statezip       4600 non-null   object \n",
      " 17  country        4600 non-null   object \n",
      "dtypes: float64(4), int64(9), object(5)\n",
      "memory usage: 647.0+ KB\n",
      "\n",
      "Data types and missing values:\n",
      "None\n",
      "\n",
      "Basic statistics:\n",
      "              price     bedrooms    bathrooms   sqft_living      sqft_lot  \\\n",
      "count  4.600000e+03  4600.000000  4600.000000   4600.000000  4.600000e+03   \n",
      "mean   5.519630e+05     3.400870     2.160815   2139.346957  1.485252e+04   \n",
      "std    5.638347e+05     0.908848     0.783781    963.206916  3.588444e+04   \n",
      "min    0.000000e+00     0.000000     0.000000    370.000000  6.380000e+02   \n",
      "25%    3.228750e+05     3.000000     1.750000   1460.000000  5.000750e+03   \n",
      "50%    4.609435e+05     3.000000     2.250000   1980.000000  7.683000e+03   \n",
      "75%    6.549625e+05     4.000000     2.500000   2620.000000  1.100125e+04   \n",
      "max    2.659000e+07     9.000000     8.000000  13540.000000  1.074218e+06   \n",
      "\n",
      "            floors   waterfront         view    condition   sqft_above  \\\n",
      "count  4600.000000  4600.000000  4600.000000  4600.000000  4600.000000   \n",
      "mean      1.512065     0.007174     0.240652     3.451739  1827.265435   \n",
      "std       0.538288     0.084404     0.778405     0.677230   862.168977   \n",
      "min       1.000000     0.000000     0.000000     1.000000   370.000000   \n",
      "25%       1.000000     0.000000     0.000000     3.000000  1190.000000   \n",
      "50%       1.500000     0.000000     0.000000     3.000000  1590.000000   \n",
      "75%       2.000000     0.000000     0.000000     4.000000  2300.000000   \n",
      "max       3.500000     1.000000     4.000000     5.000000  9410.000000   \n",
      "\n",
      "       sqft_basement     yr_built  yr_renovated  \n",
      "count    4600.000000  4600.000000   4600.000000  \n",
      "mean      312.081522  1970.786304    808.608261  \n",
      "std       464.137228    29.731848    979.414536  \n",
      "min         0.000000  1900.000000      0.000000  \n",
      "25%         0.000000  1951.000000      0.000000  \n",
      "50%         0.000000  1976.000000      0.000000  \n",
      "75%       610.000000  1997.000000   1999.000000  \n",
      "max      4820.000000  2014.000000   2014.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"D:/1_1_DS_AI_Internship/data/house_price.csv\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"=\" * 50)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\\n{df.head()}\")\n",
    "print(f\"\\nData types and missing values:\\n{df.info()}\")\n",
    "print(f\"\\nBasic statistics:\\n{df.describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee83fda7",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "In this step, we separate our data into:\n",
    "- **Features (X)**: All columns except 'price' (the target variable)\n",
    "- **Target (y)**: Only the 'price' column\n",
    "\n",
    "This separation is crucial for supervised learning as the model learns to predict `y` (price) based on `X` (features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4306f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DATA PREPARATION\n",
      "==================================================\n",
      "\n",
      "Features (X) shape: (4600, 12)\n",
      "Features (X) columns: ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated']\n",
      "\n",
      "Target (y) shape: (4600,)\n",
      "Target variable: 'price'\n",
      "\n",
      "First 5 feature values:\n",
      "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
      "0       3.0       1.50         1340      7912     1.5           0     0   \n",
      "1       5.0       2.50         3650      9050     2.0           0     4   \n",
      "2       3.0       2.00         1930     11947     1.0           0     0   \n",
      "3       3.0       2.25         2000      8030     1.0           0     0   \n",
      "4       4.0       2.50         1940     10500     1.0           0     0   \n",
      "\n",
      "   condition  sqft_above  sqft_basement  yr_built  yr_renovated  \n",
      "0          3        1340              0      1955          2005  \n",
      "1          5        3370            280      1921             0  \n",
      "2          4        1930              0      1966             0  \n",
      "3          4        1000           1000      1963             0  \n",
      "4          4        1140            800      1976          1992  \n",
      "\n",
      "First 5 target values:\n",
      "[ 313000. 2384000.  342000.  420000.  550000.]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Select numeric columns only (to avoid errors with text data)\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Step 2: Remove rows with missing values to ensure clean data\n",
    "numeric_df = numeric_df.dropna()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"DATA PREPARATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Step 3: Create X (features) by dropping the target column 'price'\n",
    "X = numeric_df.drop(columns=['price'])\n",
    "print(f\"\\nFeatures (X) shape: {X.shape}\")\n",
    "print(f\"Features (X) columns: {list(X.columns)}\")\n",
    "\n",
    "# Step 4: Create y (target) by isolating only the 'price' column\n",
    "y = numeric_df['price']\n",
    "print(f\"\\nTarget (y) shape: {y.shape}\")\n",
    "print(f\"Target variable: 'price'\")\n",
    "print(f\"\\nFirst 5 feature values:\\n{X.head()}\")\n",
    "print(f\"\\nFirst 5 target values:\\n{y.head().values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d339430",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split\n",
    "\n",
    "We split the data into:\n",
    "- **Training Set (80%)**: Used to train the model\n",
    "- **Test Set (20%)**: Used to evaluate the model's performance on unseen data\n",
    "\n",
    "This prevents overfitting and gives us a realistic measure of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc9e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TRAIN-TEST SPLIT\n",
      "==================================================\n",
      "\n",
      "Training set size: 3680 samples (80.0%)\n",
      "Test set size: 920 samples (20.0%)\n",
      "\n",
      "Training features shape: (3680, 12)\n",
      "Test features shape: (920, 12)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples ({(X_train.shape[0]/len(X))*100:.1f}%)\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples ({(X_test.shape[0]/len(X))*100:.1f}%)\")\n",
    "print(f\"\\nTraining features shape: {X_train.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba3f27",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling\n",
    "\n",
    "Before training the model, we normalize the features using StandardScaler. This ensures all features are on the same scale, which improves model training efficiency and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67274461",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Make predictions on training and test sets\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_train_pred = \u001b[43mmodel\u001b[49m.predict(X_train_scaled)\n\u001b[32m      3\u001b[39m y_test_pred = model.predict(X_test_scaled)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Calculate performance metrics\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions on training and test sets\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"PREDICTION & MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nTRAINING SET PERFORMANCE:\")\n",
    "print(f\"  Mean Squared Error (MSE): ${train_mse:,.2f}\")\n",
    "print(f\"  Root Mean Squared Error (RMSE): ${train_rmse:,.2f}\")\n",
    "print(f\"  R² Score: {train_r2:.4f}\")\n",
    "\n",
    "print(\"\\nTEST SET PERFORMANCE:\")\n",
    "print(f\"  Mean Squared Error (MSE): ${test_mse:,.2f}\")\n",
    "print(f\"  Root Mean Squared Error (RMSE): ${test_rmse:,.2f}\")\n",
    "print(f\"  R² Score: {test_r2:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\" * 50)\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual Price': y_test.values[:10],\n",
    "    'Predicted Price': y_test_pred[:10],\n",
    "    'Difference': y_test.values[:10] - y_test_pred[:10],\n",
    "    'Error %': (abs(y_test.values[:10] - y_test_pred[:10]) / y_test.values[:10] * 100)\n",
    "})\n",
    "print(\"\\n\", comparison.to_string())\n",
    "print(f\"\\nAverage prediction error on test set: ${abs(y_test.values - y_test_pred).mean():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce73527",
   "metadata": {},
   "source": [
    "## 5. Prediction & Model Evaluation\n",
    "\n",
    "We make predictions on both the training and test sets, then evaluate performance using:\n",
    "- **Mean Squared Error (MSE)**: Average squared difference between predicted and actual values\n",
    "- **Root Mean Squared Error (RMSE)**: Square root of MSE, in the same units as the target variable\n",
    "- **R² Score**: Proportion of variance explained by the model (0-1, higher is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ac5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL TRAINING\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nModel trained successfully!\")\n",
    "print(f\"Number of features: {len(model.coef_)}\")\n",
    "print(f\"\\nTop 5 feature coefficients:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "print(feature_importance.head())\n",
    "print(f\"\\nModel intercept: ${model.intercept_:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae96fa76",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "We train a Linear Regression model on the scaled training data. The model learns the relationship between the features and the target variable (house prices) by finding optimal coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44182efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"FEATURE SCALING\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nOriginal training features (first 3 rows):\\n{X_train.head(3)}\")\n",
    "print(f\"\\nScaled training features (first 3 rows):\\n{X_train_scaled[:3]}\")\n",
    "print(f\"\\nFeature means after scaling: {X_train_scaled.mean(axis=0)[:5]}\")\n",
    "print(f\"Feature std devs after scaling: {X_train_scaled.std(axis=0)[:5]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
